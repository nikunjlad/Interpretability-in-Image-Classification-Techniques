

Understanding Interpretability
==============================

.. toctree::
   :maxdepth: 2

An important question to ask when pursuing research is **Why?** followed by **How?**. Why does this algorithm work?
How different is it from other algorithms? What is Image Segmentation in contrast to Object Detection and what goes inside
the black box models? More specifically, there was one question always running in the back of my mind - "How the heck
does this work and why?". To give you more clarity as to why this question keeps lingering in my mind, let me recall
few scenarios why you too should be having this question in your mind.

Say you are travelling in a subway and all of a sudden you find the police narrowing down on the person sitting
next to you. You wonder what just happenend and why was that person arrested. Turns out the face recognition software in
the camera mounted in the subway recognized the person next to you as a wanted criminal and notified the police with his
real time location. While everyone is happy and feeling safe that a criminal is arrested, how often do you ask a question -
"How the camera figure out the person was criminal?".

Let me give you another example. Say, you are fond of plants and you are a tree lover. You have a garden of your own and
since you are new to growing plants and you are not aware of plant species you happen to download an android application
to identify plant species. This application gives you information of plant characteristics, the weather best suitable for
its growth, the frequency at which you have to give it fertilizers and pesticides or water to keep it healthy. You point your
phone camera to a plant you just bought and the app gives a notification to water it twice everyday and to keep it in
sunlight. Moreover, it also suggests you to cut out the weed growing around the other plants of yours when you capture
the dying leaves on those plants which are slowing turning yellowish. Wouldn't you be surprised by how wizardly this
app is to let you insights of your plants and potentially save you your money. "How does it work internally and why so?".

What is Interpretability?
-------------------------

Challenges faced by current deep neural networks
------------------------------------------------

How Interpretability helps demystify black box models?
------------------------------------------------------


Understanding Explainability and its relation with Interpretability
-------------------------------------------------------------------
